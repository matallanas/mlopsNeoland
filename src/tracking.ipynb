{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLOps or how not to die to put models in production"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## MLFlow Tracking\n",
    "This notebook shows some examples of using mlflow library to track useful information about machine learning experiments.\n",
    "\n",
    "It is necessary to install mlflow (``pip install mlflow``) in the working environment or directly over a simple Python installation."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic example\n",
    "This example show a basic use of mlflow to start an experiment, track parameters and track metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In general, it is not necessary to explicitly call ```mlflow.create_experiment('name')``` before setting it. We can just set the experiment and mlflow will create it if not existed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('test_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run =  mlflow.start_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Another alternative is:\n",
    "```python\n",
    "with mlflow.start_run() as run:\n",
    "    ...\n",
    "```\n",
    "This way prevents calling ``mlflow.end_run()`` to finish the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_param('param1', 1)\n",
    "mlflow.log_metric('metric1', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_param('param1', 1)\n",
    "mlflow.log_metric('metric1', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Breast cancer: Scikit-learn\n",
    "Now, some models will be trained on breast cancer dataset.\n",
    "\n",
    "So, again, a new experiment is necessary for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('breast_cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(cancer.data)\n",
    "y = np.array(cancer.target)\n",
    "print(f'X: {X.shape}, y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=426, test_size=143, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "After splitting the dataset, it is necessary to apply a feature scaling to improve the model's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next function computes three of the most used measures in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, x_test, y_test):    \n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    return precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First model relies on a Logistic Regression, which is the most used model as baseline for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Logistic Regression\n",
    "def breast_cancer_lr(solver=\"lbfgs\", C=1.0):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import mlflow.sklearn\n",
    "    with mlflow.start_run() as run:\n",
    "        lr = LogisticRegression(solver = solver, C = C)\n",
    "        mlflow.log_param(\"solver\", solver)\n",
    "        mlflow.log_param(\"C\", C)\n",
    "        mlflow.set_tag(\"model type\", \"sklearn - LogisticRegression\")\n",
    "        lr.fit(x_train, y_train)\n",
    "        precision, recall, accuracy = validate_model(lr, x_test, y_test)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.sklearn.log_model(lr, \"model\")\n",
    "        print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "And, for example, we can train it three times with different parameters to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_lr(solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_lr(solver=\"liblinear\", C=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The second model relies on Random Forest, which is another example of widely used machine learning model for both regression and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Random Forest\n",
    "def breast_cancer_rf(n_estimators=100, max_depth=2, criterion=\"gini\"):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import mlflow.sklearn\n",
    "    with mlflow.start_run() as run:\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion=criterion)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"criterion\", criterion)\n",
    "        mlflow.set_tag(\"model type\", \"sklearn - RandomForest\")\n",
    "        clf.fit(x_train, y_train)\n",
    "        precision, recall, accuracy = validate_model(clf, x_test, y_test)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.sklearn.log_model(clf, \"model\")\n",
    "        print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Again, it is a good idea to train it three times with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_rf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_rf(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_rf(n_estimators=500, criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, we're going to change the kind of model to show an interesting feature of MLFlow Tracking: tracking step.\n",
    "\n",
    "A tracking step is a log that contains information about a specific iteration during the training process. For instance, in forward backward propagation algorithm to train neural network, several iterations (or epochs) of the same algorithm are execute in order to optimise the neural network weights step by step. The goal is to optimise the loss function to obtain the best effectiveness in the corresponding problem.\n",
    "\n",
    "In this case, a MultiLayer Perceptron with a unique neuron as output is used. The class ``LossHistory`` is a callback class that defines the behaviour during the epochs of the training process. In this case, we are going to track loss, validation accuracy, and the so-called measures over the test set: precision, recall and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Keras\n",
    "from keras.callbacks import Callback\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs.get('loss')\n",
    "        acc = logs.get('accuracy')\n",
    "        mlflow.log_metric(\"loss\", loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", acc, step=epoch)\n",
    "        precision, recall, accuracy = validate_model(self.model, x_test, y_test)        \n",
    "        mlflow.log_metric(\"precision\", precision, step=epoch)\n",
    "        mlflow.log_metric(\"recall\", recall, step=epoch)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy, step=epoch)\n",
    "        self.losses.append(loss)\n",
    "    \n",
    "\n",
    "def breast_cancer_keras(optimizer='adam',dropout=0.00, nb_epoch=20):\n",
    "    import mlflow.keras\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.set_tag(\"model type\", \"keras - MLP\")\n",
    "        model = Sequential()\n",
    "        # Adding the input layer and the first hidden layer\n",
    "        model.add(Dense(output_dim=16, init='uniform', activation='relu', input_dim=30))\n",
    "        # Adding dropout to prevent overfitting\n",
    "        model.add(Dropout(p=dropout))\n",
    "        # Adding the second hidden layer\n",
    "        model.add(Dense(output_dim=16, init='uniform', activation='relu'))\n",
    "        # Adding dropout to prevent overfitting\n",
    "        model.add(Dropout(p=dropout))\n",
    "        # Adding the output layer\n",
    "        model.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "        # Compiling the ANN\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        history = LossHistory()\n",
    "        model.fit(x_train, y_train, batch_size=100, nb_epoch=nb_epoch, callbacks=[history])\n",
    "        mlflow.log_param(\"optimizer\", optimizer)\n",
    "        mlflow.log_param(\"dropout\", dropout)\n",
    "        mlflow.keras.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As before, the model is trained three times with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_keras(nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_keras(optimizer='sgd', dropout=0.4, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, the \"model\" is a little bit different: it is a custom code to compute the model output. In this case, we defined a random strategy to predict the output value, just to compare with the previous models.\n",
    "\n",
    "This model must be defined as a method ``predict`` inside a class that inherits from ``mlflow.pyfunc.PythonModel``. PyFunc is the MLFlow API for custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Custom model\n",
    "import mlflow.pyfunc\n",
    "from numpy import random\n",
    "class CustomClassifier(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def predict(self, model_input):\n",
    "        return np.random.randint(2, size=len(model_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Furthermore, we want now to save the dataset that was used to train the models, so we create with this method temporary files in numpy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    "def save_numpy_array(np_array):\n",
    "    outfile = NamedTemporaryFile()\n",
    "    np.save(outfile, np_array)\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This model doesn't have a train execution so, we can directly log its results, the model, and the dataset's files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    ccl = CustomClassifier()\n",
    "    precision, recall, accuracy = validate_model(ccl, x_test, y_test)\n",
    "    mlflow.set_tag(\"model type\", \"pyfunc - random\")\n",
    "    mlflow.set_tag(\"dataset_uri\", \"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\")\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1\", (2 * precision * recall / (precision + recall))) # new metric for this model\n",
    "    # Log custom model by means of pyfunc api\n",
    "    mlflow.pyfunc.log_model(\"model\", python_model=ccl)\n",
    "    # Log dataset and splits used to train/test\n",
    "    x_train_file = save_numpy_array(x_train)\n",
    "    x_test_file = save_numpy_array(x_test)\n",
    "    y_train_file = save_numpy_array(y_train)\n",
    "    y_test_file = save_numpy_array(y_test)\n",
    "    mlflow.log_artifact(x_train_file.name, \"dataset/x_train\")\n",
    "    mlflow.log_artifact(x_test_file.name, \"dataset/x_test\")\n",
    "    mlflow.log_artifact(y_train_file.name, \"dataset/y_train\")\n",
    "    mlflow.log_artifact(y_test_file.name, \"dataset/y_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}